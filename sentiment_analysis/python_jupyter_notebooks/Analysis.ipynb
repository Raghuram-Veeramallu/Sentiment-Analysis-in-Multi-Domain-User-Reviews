{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing the data and models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk import FreqDist\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"books\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>summary</th>\n",
       "      <th>review_text</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>helpful</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniq_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1593760361:beautiful:krissy_\"avid_reader\"</th>\n",
       "      <td>Hannah Coulter: A Novel: Books: Wendell Berry</td>\n",
       "      <td>Beautiful</td>\n",
       "      <td>This book was stunning - I was enraptured with...</td>\n",
       "      <td>Krissy \"Avid Reader\"</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0312307411:laughs,_gasps,_aha's_and_oy_veys:m._stricks</th>\n",
       "      <td>Born to Kvetch: Yiddish Language and Culture i...</td>\n",
       "      <td>Laughs, gasps, aha's and oy veys</td>\n",
       "      <td>Born to Kvetch is, at one time, informative, e...</td>\n",
       "      <td>M. Stricks</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417718544:vastly_over-written_and_vastly_over-praised:paul_cook</th>\n",
       "      <td>Independence Day: Books: Richard Ford</td>\n",
       "      <td>Vastly Over-Written and Vastly Over-Praised</td>\n",
       "      <td>From the remarks at this site, people either l...</td>\n",
       "      <td>Paul Cook</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                         product_name  \\\n",
       "uniq_id                                                                                                 \n",
       "1593760361:beautiful:krissy_\"avid_reader\"               Hannah Coulter: A Novel: Books: Wendell Berry   \n",
       "0312307411:laughs,_gasps,_aha's_and_oy_veys:m._...  Born to Kvetch: Yiddish Language and Culture i...   \n",
       "1417718544:vastly_over-written_and_vastly_over-...              Independence Day: Books: Richard Ford   \n",
       "\n",
       "                                                                                        summary  \\\n",
       "uniq_id                                                                                           \n",
       "1593760361:beautiful:krissy_\"avid_reader\"                                             Beautiful   \n",
       "0312307411:laughs,_gasps,_aha's_and_oy_veys:m._...             Laughs, gasps, aha's and oy veys   \n",
       "1417718544:vastly_over-written_and_vastly_over-...  Vastly Over-Written and Vastly Over-Praised   \n",
       "\n",
       "                                                                                          review_text  \\\n",
       "uniq_id                                                                                                 \n",
       "1593760361:beautiful:krissy_\"avid_reader\"           This book was stunning - I was enraptured with...   \n",
       "0312307411:laughs,_gasps,_aha's_and_oy_veys:m._...  Born to Kvetch is, at one time, informative, e...   \n",
       "1417718544:vastly_over-written_and_vastly_over-...  From the remarks at this site, people either l...   \n",
       "\n",
       "                                                                reviewer  \\\n",
       "uniq_id                                                                    \n",
       "1593760361:beautiful:krissy_\"avid_reader\"           Krissy \"Avid Reader\"   \n",
       "0312307411:laughs,_gasps,_aha's_and_oy_veys:m._...            M. Stricks   \n",
       "1417718544:vastly_over-written_and_vastly_over-...             Paul Cook   \n",
       "\n",
       "                                                    helpful  rating  sentiment  \n",
       "uniq_id                                                                         \n",
       "1593760361:beautiful:krissy_\"avid_reader\"                 0       5          1  \n",
       "0312307411:laughs,_gasps,_aha's_and_oy_veys:m._...      100       5          1  \n",
       "1417718544:vastly_over-written_and_vastly_over-...       66       2          0  "
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('../data/full_data/'+category+'.csv')\n",
    "train_data = train_data.set_index('uniq_id')\n",
    "train_data = train_data.drop('Unnamed: 0', axis = 1)\n",
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>helpful</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1998.000000</td>\n",
       "      <td>1998.000000</td>\n",
       "      <td>1998.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>53.227227</td>\n",
       "      <td>3.096597</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>38.548273</td>\n",
       "      <td>1.701329</td>\n",
       "      <td>0.500125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           helpful       rating    sentiment\n",
       "count  1998.000000  1998.000000  1998.000000\n",
       "mean     53.227227     3.096597     0.500000\n",
       "std      38.548273     1.701329     0.500125\n",
       "min       0.000000     1.000000     0.000000\n",
       "25%      14.000000     1.000000     0.000000\n",
       "50%      54.000000     3.000000     0.500000\n",
       "75%     100.000000     5.000000     1.000000\n",
       "max     100.000000     5.000000     1.000000"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_words(x):\n",
    "    all_words = ' '.join([text for text in x])\n",
    "    all_words = all_words.split()\n",
    "\n",
    "    fdist = FreqDist(all_words)\n",
    "    words_df = pd.DataFrame({'word':list(fdist.keys()), 'count':list(fdist.values())})\n",
    "\n",
    "    # Select top 20 most frequent words\n",
    "    d = words_df.nlargest(columns=\"count\", n = 20) \n",
    "    plt.figure(figsize=(20,5))\n",
    "    ax = sns.barplot(data=d, x= \"word\", y = \"count\")\n",
    "    ax.set(ylabel = 'Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq_words(train_data['review_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_sym = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "rep_unw_sym = re.compile('[^0-9a-z #+_]')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "train_data['summary'] = train_data['summary'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "train_data['review_text'] = train_data['review_text'].str.replace(\"[^a-zA-Z#]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    # Change all text to lower to avoid ambiguity\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Replace all unwanted symbols by space in text\n",
    "    text = rep_sym.sub(' ', text) \n",
    "    text = rep_unw_sym.sub('', text)\n",
    "    \n",
    "    # Remove stopwords from the sentences\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the text for stop words\n",
    "train_data['summary'] = train_data['summary'].apply(clean_text)\n",
    "train_data['review_text'] = train_data['review_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "freq_words(train_data['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "freq_words(train_data['review_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Various Models over the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rockstar/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# Library to split the training data to train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Library to convert the text into a matrix of TF-IDF and token count.\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Library to apply a pipeline of functions\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Libraries to perform Learning on the data\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Library to evaluate the model predictions\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rev, X_test_rev, y_train, y_test = train_test_split(train_data.review_text,\n",
    "                                                    train_data.sentiment,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.782\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.84      0.79       246\n",
      "          1       0.82      0.73      0.77       254\n",
      "\n",
      "avg / total       0.79      0.78      0.78       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB())])\n",
    "\n",
    "# Fit the training data on the model\n",
    "nb.fit(X_train_rev, y_train)\n",
    "\n",
    "# Predict the labels for the test data split using train test split\n",
    "y_pred = nb.predict(X_test_rev)         \n",
    "\n",
    "# Evaluate the results\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.788\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.76      0.78       246\n",
      "          1       0.78      0.82      0.80       254\n",
      "\n",
      "avg / total       0.79      0.79      0.79       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None))])\n",
    "\n",
    "\n",
    "# Fit the training data on the model\n",
    "sgd.fit(X_train_rev, y_train)\n",
    "\n",
    "# Predict the labels for the test data split using train test split\n",
    "y_pred = sgd.predict(X_test_rev)\n",
    "\n",
    "# Evaluate the results\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.778\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.76      0.77       246\n",
      "          1       0.78      0.79      0.78       254\n",
      "\n",
      "avg / total       0.78      0.78      0.78       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5))])\n",
    "\n",
    "# Fit the training data on the model\n",
    "logreg.fit(X_train_rev, y_train)\n",
    "\n",
    "# Predict the labels for the test data split using train test split\n",
    "y_pred = logreg.predict(X_test_rev)\n",
    "\n",
    "# Evaluate the results\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.748\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.74      0.74       246\n",
      "          1       0.75      0.75      0.75       254\n",
      "\n",
      "avg / total       0.75      0.75      0.75       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "rfc = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', RandomForestClassifier(n_estimators=100))])\n",
    "\n",
    "# Fit the training data on the model\n",
    "rfc.fit(X_train_rev, y_train)\n",
    "\n",
    "# Predict the labels for the test data split using train test split\n",
    "y_pred = rfc.predict(X_test_rev)\n",
    "\n",
    "# Evaluate the results\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sum, X_test_sum, y_train, y_test = train_test_split(train_data.summary,\n",
    "                                                    train_data.sentiment,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.748\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.72      0.73       236\n",
      "          1       0.76      0.77      0.76       264\n",
      "\n",
      "avg / total       0.75      0.75      0.75       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB())])\n",
    "\n",
    "# Fit the training data on the model\n",
    "nb.fit(X_train_sum, y_train)\n",
    "\n",
    "# Predict the labels for the test data split using train test split\n",
    "y_pred = nb.predict(X_test_sum)         \n",
    "\n",
    "# Evaluate the results\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.744\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.78      0.74       236\n",
      "          1       0.78      0.71      0.75       264\n",
      "\n",
      "avg / total       0.75      0.74      0.74       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None))])\n",
    "\n",
    "\n",
    "# Fit the training data on the model\n",
    "sgd.fit(X_train_sum, y_train)\n",
    "\n",
    "# Predict the labels for the test data split using train test split\n",
    "y_pred = sgd.predict(X_test_sum)\n",
    "\n",
    "# Evaluate the results\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.71      0.69       236\n",
      "          1       0.73      0.69      0.71       264\n",
      "\n",
      "avg / total       0.70      0.70      0.70       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5))])\n",
    "\n",
    "# Fit the training data on the model\n",
    "logreg.fit(X_train_sum, y_train)\n",
    "\n",
    "# Predict the labels for the test data split using train test split\n",
    "y_pred = logreg.predict(X_test_sum)\n",
    "\n",
    "# Evaluate the results\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.738\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.81      0.74       236\n",
      "          1       0.80      0.68      0.73       264\n",
      "\n",
      "avg / total       0.75      0.74      0.74       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "rfc = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', RandomForestClassifier(n_estimators=100))])\n",
    "\n",
    "# Fit the training data on the model\n",
    "rfc.fit(X_train_sum, y_train)\n",
    "\n",
    "# Predict the labels for the test data split using train test split\n",
    "y_pred = rfc.predict(X_test_sum)\n",
    "\n",
    "# Evaluate the results\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using both reviews and summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec_rev = CountVectorizer(stop_words = \"english\").fit(X_train_rev)\n",
    "cvec_sum = CountVectorizer(stop_words = \"english\").fit(X_train_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_train = pd.DataFrame(cvec_rev.transform(X_train_rev).todense(), columns = cvec_rev.get_feature_names())\n",
    "rev_test = pd.DataFrame(cvec_rev.transform(X_test_rev).todense(), columns = cvec_rev.get_feature_names())\n",
    "sum_train = pd.DataFrame(cvec_sum.transform(X_train_sum).todense(), columns = cvec_sum.get_feature_names())\n",
    "sum_test = pd.DataFrame(cvec_sum.transform(X_test_sum).todense(), columns = cvec_sum.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([rev_train, sum_train], axis = 1)\n",
    "X_test = pd.concat([rev_test, sum_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.842\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.81      0.83       236\n",
      "          1       0.84      0.87      0.85       264\n",
      "\n",
      "avg / total       0.84      0.84      0.84       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators = 100)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.81\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.81      0.80       236\n",
      "          1       0.83      0.81      0.82       264\n",
      "\n",
      "avg / total       0.81      0.81      0.81       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.804\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.77      0.79       236\n",
      "          1       0.80      0.84      0.82       264\n",
      "\n",
      "avg / total       0.80      0.80      0.80       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)\n",
    "sgd.fit(X_train, y_train)\n",
    "y_pred = sgd.predict(X_test)\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.804\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.78      0.79       236\n",
      "          1       0.81      0.82      0.82       264\n",
      "\n",
      "avg / total       0.80      0.80      0.80       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)         \n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rev, X_test_rev, y_train_rev, y_test_rev = train_test_split(train_data.review_text,\n",
    "                                                    train_data.rating,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.444\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.25      0.36       126\n",
      "          2       1.00      0.02      0.03       120\n",
      "          4       0.00      0.00      0.00        64\n",
      "          5       0.42      0.99      0.59       190\n",
      "\n",
      "avg / total       0.57      0.44      0.32       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rockstar/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB())])\n",
    "\n",
    "# Fit the training data on the model\n",
    "nb.fit(X_train_rev, y_train_rev)\n",
    "\n",
    "# Predict the labels for the test data split using train test split\n",
    "y_pred = nb.predict(X_test_rev)         \n",
    "\n",
    "# Evaluate the results\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test_rev))\n",
    "print(classification_report(y_test_rev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.552\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.63      0.58       126\n",
      "          2       0.50      0.23      0.32       120\n",
      "          4       0.50      0.05      0.09        64\n",
      "          5       0.57      0.87      0.69       190\n",
      "\n",
      "avg / total       0.54      0.55      0.50       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None))])\n",
    "\n",
    "\n",
    "# Fit the training data on the model\n",
    "sgd.fit(X_train_rev, y_train_rev)\n",
    "\n",
    "# Predict the labels for the test data split using train test split\n",
    "y_pred = sgd.predict(X_test_rev)\n",
    "\n",
    "# Evaluate the results\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test_rev))\n",
    "print(classification_report(y_test_rev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       246\n",
      "          1       0.19      0.10      0.13       254\n",
      "          2       0.00      0.00      0.00         0\n",
      "          4       0.00      0.00      0.00         0\n",
      "          5       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.10      0.05      0.07       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rockstar/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/rockstar/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5))])\n",
    "\n",
    "# Fit the training data on the model\n",
    "logreg.fit(X_train_rev, y_train_rev)\n",
    "\n",
    "# Predict the labels for the test data split using train test split\n",
    "y_pred = logreg.predict(X_test_rev)\n",
    "\n",
    "# Evaluate the results\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test_rev))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.524\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.48      0.56      0.52       126\n",
      "          2       0.68      0.21      0.32       120\n",
      "          4       1.00      0.02      0.03        64\n",
      "          5       0.52      0.87      0.65       190\n",
      "\n",
      "avg / total       0.61      0.52      0.46       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "rfc = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', RandomForestClassifier(n_estimators=100))])\n",
    "\n",
    "# Fit the training data on the model\n",
    "rfc.fit(X_train_rev, y_train_rev)\n",
    "\n",
    "# Predict the labels for the test data split using train test split\n",
    "y_pred = rfc.predict(X_test_rev)\n",
    "\n",
    "# Evaluate the results\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test_rev))\n",
    "print(classification_report(y_test_rev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.376\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.35      0.39      0.37       126\n",
      "          2       0.30      0.33      0.31       120\n",
      "          4       0.20      0.12      0.15        64\n",
      "          5       0.49      0.48      0.49       190\n",
      "\n",
      "avg / total       0.37      0.38      0.37       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "dt = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', DecisionTreeClassifier())])\n",
    "\n",
    "# Fit the training data on the model\n",
    "dt.fit(X_train_rev, y_train_rev)\n",
    "\n",
    "# Predict the labels for the test data split using train test split\n",
    "y_pred = dt.predict(X_test_rev)\n",
    "\n",
    "# Evaluate the results\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test_rev))\n",
    "print(classification_report(y_test_rev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.368\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.31      0.36      0.33       126\n",
      "          2       0.32      0.29      0.30       120\n",
      "          4       0.22      0.20      0.21        64\n",
      "          5       0.49      0.48      0.48       190\n",
      "\n",
      "avg / total       0.37      0.37      0.37       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "knn = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', KNeighborsClassifier())])\n",
    "\n",
    "# Fit the training data on the model\n",
    "dt.fit(X_train_rev, y_train_rev)\n",
    "\n",
    "# Predict the labels for the test data split using train test split\n",
    "y_pred = dt.predict(X_test_rev)\n",
    "\n",
    "# Evaluate the results\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test_rev))\n",
    "print(classification_report(y_test_rev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.432\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.41      0.36      0.38       126\n",
      "          2       0.41      0.34      0.37       120\n",
      "          4       0.35      0.14      0.20        64\n",
      "          5       0.46      0.64      0.53       190\n",
      "\n",
      "avg / total       0.42      0.43      0.41       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "ada = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', AdaBoostClassifier(n_estimators=100))])\n",
    "\n",
    "# Fit the training data on the model\n",
    "ada.fit(X_train_rev, y_train_rev)\n",
    "\n",
    "# Predict the labels for the test data split using train test split\n",
    "y_pred = ada.predict(X_test_rev)\n",
    "\n",
    "# Evaluate the results\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test_rev))\n",
    "print(classification_report(y_test_rev, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sum, X_test_sum, y_train_sum, y_test_sum = train_test_split(train_data.summary,\n",
    "                                                    train_data.rating,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.574\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.66      0.62       175\n",
      "          2       0.25      0.01      0.03        73\n",
      "          4       0.50      0.02      0.03        56\n",
      "          5       0.57      0.86      0.69       196\n",
      "\n",
      "avg / total       0.52      0.57      0.49       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB())])\n",
    "\n",
    "# Fit the training data on the model\n",
    "nb.fit(X_train_sum, y_train_sum)\n",
    "\n",
    "# Predict the labels for the test data split using train test split\n",
    "y_pred = nb.predict(X_test_sum)         \n",
    "\n",
    "# Evaluate the results\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test_sum))\n",
    "print(classification_report(y_test_sum, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.556\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.73      0.62       175\n",
      "          2       0.24      0.10      0.14        73\n",
      "          4       0.17      0.07      0.10        56\n",
      "          5       0.65      0.71      0.68       196\n",
      "\n",
      "avg / total       0.50      0.56      0.52       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None))])\n",
    "\n",
    "\n",
    "# Fit the training data on the model\n",
    "sgd.fit(X_train_sum, y_train_sum)\n",
    "\n",
    "# Predict the labels for the test data split using train test split\n",
    "y_pred = sgd.predict(X_test_sum)\n",
    "\n",
    "# Evaluate the results\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test_sum))\n",
    "print(classification_report(y_test_sum, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.494\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.57      0.54       175\n",
      "          2       0.21      0.16      0.18        73\n",
      "          4       0.21      0.21      0.21        56\n",
      "          5       0.64      0.63      0.63       196\n",
      "\n",
      "avg / total       0.49      0.49      0.49       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5))])\n",
    "\n",
    "# Fit the training data on the model\n",
    "logreg.fit(X_train_sum, y_train_sum)\n",
    "\n",
    "# Predict the labels for the test data split using train test split\n",
    "y_pred = logreg.predict(X_test_sum)\n",
    "\n",
    "# Evaluate the results\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test_sum))\n",
    "print(classification_report(y_test_sum, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.516\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.69      0.57       175\n",
      "          2       0.26      0.19      0.22        73\n",
      "          4       0.34      0.18      0.24        56\n",
      "          5       0.66      0.58      0.62       196\n",
      "\n",
      "avg / total       0.51      0.52      0.50       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "rfc = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', RandomForestClassifier(n_estimators=100))])\n",
    "\n",
    "# Fit the training data on the model\n",
    "rfc.fit(X_train_sum, y_train_sum)\n",
    "\n",
    "# Predict the labels for the test data split using train test split\n",
    "y_pred = rfc.predict(X_test_sum)\n",
    "\n",
    "# Evaluate the results\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test_sum))\n",
    "print(classification_report(y_test_sum, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using both reviews and summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec_rev = CountVectorizer(stop_words = \"english\").fit(X_train_rev)\n",
    "cvec_sum = CountVectorizer(stop_words = \"english\").fit(X_train_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_train = pd.DataFrame(cvec_rev.transform(X_train_rev).todense(), columns = cvec_rev.get_feature_names())\n",
    "rev_test = pd.DataFrame(cvec_rev.transform(X_test_rev).todense(), columns = cvec_rev.get_feature_names())\n",
    "sum_train = pd.DataFrame(cvec_sum.transform(X_train_sum).todense(), columns = cvec_sum.get_feature_names())\n",
    "sum_test = pd.DataFrame(cvec_sum.transform(X_test_sum).todense(), columns = cvec_sum.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([rev_train, sum_train], axis = 1)\n",
    "X_test = pd.concat([rev_test, sum_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.664\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.89      0.75       175\n",
      "          2       1.00      0.03      0.05        73\n",
      "          4       0.67      0.04      0.07        56\n",
      "          5       0.68      0.88      0.77       196\n",
      "\n",
      "avg / total       0.71      0.66      0.58       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators = 100)\n",
    "rfc.fit(X_train, y_train_rev)\n",
    "y_pred = rfc.predict(X_test)\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test_rev))\n",
    "print(classification_report(y_test_rev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.616\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.72      0.71       175\n",
      "          2       0.29      0.23      0.26        73\n",
      "          4       0.25      0.23      0.24        56\n",
      "          5       0.73      0.78      0.75       196\n",
      "\n",
      "avg / total       0.60      0.62      0.61       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(X_train, y_train_rev)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test_rev))\n",
    "print(classification_report(y_test_rev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.632\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.72      0.70       175\n",
      "          2       0.27      0.26      0.26        73\n",
      "          4       0.39      0.34      0.36        56\n",
      "          5       0.78      0.78      0.78       196\n",
      "\n",
      "avg / total       0.63      0.63      0.63       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)\n",
    "sgd.fit(X_train, y_train_rev)\n",
    "y_pred = sgd.predict(X_test)\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test_rev))\n",
    "print(classification_report(y_test_rev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.67\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       175\n",
      "          2       0.39      0.15      0.22        73\n",
      "          4       0.50      0.05      0.10        56\n",
      "          5       0.69      0.96      0.80       196\n",
      "\n",
      "avg / total       0.62      0.67      0.61       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train_rev)\n",
    "y_pred = nb.predict(X_test)         \n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test_rev))\n",
    "print(classification_report(y_test_rev, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Advanced Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.508\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.57      0.57       175\n",
      "          2       0.20      0.21      0.20        73\n",
      "          4       0.22      0.20      0.21        56\n",
      "          5       0.64      0.66      0.65       196\n",
      "\n",
      "avg / total       0.51      0.51      0.51       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the training data on the model\n",
    "dt.fit(X_train, y_train_rev)\n",
    "\n",
    "# Predict the labels for the test data split using train test split\n",
    "y_pred = dt.predict(X_test)         \n",
    "\n",
    "# Evaluate the results\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test_rev))\n",
    "print(classification_report(y_test_rev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.306\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.44      0.42      0.43       175\n",
      "          2       0.13      0.11      0.12        73\n",
      "          4       0.09      0.29      0.14        56\n",
      "          5       0.54      0.28      0.37       196\n",
      "\n",
      "avg / total       0.40      0.31      0.33       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "\n",
    "# Fit the training data on the model\n",
    "knn.fit(X_train, y_train_rev)\n",
    "\n",
    "# Predict the labels for the test data split using train test split\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the results\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test_rev))\n",
    "print(classification_report(y_test_rev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.564\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.72      0.64       175\n",
      "          2       0.06      0.04      0.05        73\n",
      "          4       0.44      0.27      0.33        56\n",
      "          5       0.70      0.70      0.70       196\n",
      "\n",
      "avg / total       0.54      0.56      0.54       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "adb = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "# Fit the training data on the model\n",
    "adb.fit(X_train, y_train_rev)\n",
    "\n",
    "# Predict the labels for the test data split using train test split\n",
    "y_pred = adb.predict(X_test)\n",
    "\n",
    "# Evaluate the results\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test_rev))\n",
    "print(classification_report(y_test_rev, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>summary</th>\n",
       "      <th>review_text</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>helpful</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniq_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B0001IXUEY:good_purchase:r._latham</th>\n",
       "      <td>Panasonic RX-D29 CD / Radio / Cassette Boombox...</td>\n",
       "      <td>good purchase</td>\n",
       "      <td>couldn't find a boombox that was lightweight b...</td>\n",
       "      <td>R. Latham</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00005UKBG:it_does_the_job:diane_m._chalmers</th>\n",
       "      <td>Atlantic 1316 CD Storage Case (110-Capacity, W...</td>\n",
       "      <td>It does the job</td>\n",
       "      <td>I have never had this device fall over like ot...</td>\n",
       "      <td>Diane M. Chalmers</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00006IC4E:excellent,_but_fragile:geoffrey_levine</th>\n",
       "      <td>Fellowes 21100 Book Lift Holder (Silver): Elec...</td>\n",
       "      <td>excellent, but fragile</td>\n",
       "      <td>It worked much better than expected. The page ...</td>\n",
       "      <td>Geoffrey Levine</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        product_name  \\\n",
       "uniq_id                                                                                                \n",
       "B0001IXUEY:good_purchase:r._latham                 Panasonic RX-D29 CD / Radio / Cassette Boombox...   \n",
       "B00005UKBG:it_does_the_job:diane_m._chalmers       Atlantic 1316 CD Storage Case (110-Capacity, W...   \n",
       "B00006IC4E:excellent,_but_fragile:geoffrey_levine  Fellowes 21100 Book Lift Holder (Silver): Elec...   \n",
       "\n",
       "                                                                  summary  \\\n",
       "uniq_id                                                                     \n",
       "B0001IXUEY:good_purchase:r._latham                          good purchase   \n",
       "B00005UKBG:it_does_the_job:diane_m._chalmers              It does the job   \n",
       "B00006IC4E:excellent,_but_fragile:geoffrey_levine  excellent, but fragile   \n",
       "\n",
       "                                                                                         review_text  \\\n",
       "uniq_id                                                                                                \n",
       "B0001IXUEY:good_purchase:r._latham                 couldn't find a boombox that was lightweight b...   \n",
       "B00005UKBG:it_does_the_job:diane_m._chalmers       I have never had this device fall over like ot...   \n",
       "B00006IC4E:excellent,_but_fragile:geoffrey_levine  It worked much better than expected. The page ...   \n",
       "\n",
       "                                                            reviewer  helpful  \n",
       "uniq_id                                                                        \n",
       "B0001IXUEY:good_purchase:r._latham                         R. Latham       83  \n",
       "B00005UKBG:it_does_the_job:diane_m._chalmers       Diane M. Chalmers      100  \n",
       "B00006IC4E:excellent,_but_fragile:geoffrey_levine    Geoffrey Levine      100  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('../data/test_data/test_electronics.csv')\n",
    "test_data = test_data.set_index('uniq_id')\n",
    "test_data = test_data.drop('Unnamed: 0', axis = 1)\n",
    "test_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainData(category):\n",
    "    train_data = pd.read_csv('../data/full_data/'+category+'.csv')\n",
    "    train_data = train_data.set_index('uniq_id')\n",
    "    train_data = train_data.drop('Unnamed: 0', axis = 1)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(train_data):\n",
    "    train_data['summary'] = train_data['summary'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "    train_data['review_text'] = train_data['review_text'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "    train_data['summary'] = train_data['summary'].apply(clean_text)\n",
    "    train_data['review_text'] = train_data['review_text'].apply(clean_text)\n",
    "\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(train_data, output):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data.review_text,\n",
    "                                                        output,\n",
    "                                                        test_size=0.25,\n",
    "                                                        random_state = 42)\n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['books', 'dvd', 'electronics', 'kitchen_housewares']\n",
    "data_train = pd.DataFrame()\n",
    "for cat in categories:\n",
    "    train_data = getTrainData(cat)\n",
    "    train_data = clean_data(train_data)\n",
    "    #data_train = pd.concat([data_train, train_data], axis = 1)\n",
    "    data_train = data_train.append(train_data)\n",
    "X_train, X_test, y_train, y_test = split_data(data_train, data_train.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = clean_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvec_rev = CountVectorizer(stop_words = \"english\").fit(test_data.review_text)\n",
    "# cvec_sum = CountVectorizer(stop_words = \"english\").fit(test_data.summary)\n",
    "# test_rev = pd.DataFrame(cvec_rev.transform(test_data.review_text).todense(), columns = cvec_rev.get_feature_names())\n",
    "# test_sum = pd.DataFrame(cvec_sum.transform(test_data.summary).todense(), columns = cvec_sum.get_feature_names())\n",
    "\n",
    "# test_X = pd.concat([test_rev, test_sum], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd.fit(X_train, y_train)\n",
    "y_prediction = sgd.predict(test_data.review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_data = pd.DataFrame({'uniq_id':test_data.index, 'sentiment':y_prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(data_train, data_train.rating)\n",
    "sgd.fit(X_train, y_train)\n",
    "y_pred2 = sgd.predict(test_data.review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_data = pd.DataFrame({'uniq_id':test_data.index, 'rating': y_pred2, 'sentiment':y_prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_data = sol_data.set_index('uniq_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniq_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B00008SCFU:excellent_product,_and_i_received_it_free!:just_me</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00009YUPS:don't_buy.__terrible_terrible_product:dr._marc_mayerson</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00005UKBG:nice_rack:charles_m._miller</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B0009O5MWI:awesome_value!!_highly_recommend!:s._tucker_\"dance_freak\"</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00008RW8B:excellent_and_portable_memory_card_reader:d-m-a</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00006HYUB:don't_risk_being_without_one!:theresa_l._smith</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00008SCFU:rcarrier:ronald_r._carrier</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00006IC4E:great_little_product!:jigga</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B0001IXUEY:perfect_for_my_needs:vask</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B000093IRC:great_successess_with_no_problems:snowdog_\"johnsrinx\"</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    rating  sentiment\n",
       "uniq_id                                                              \n",
       "B00008SCFU:excellent_product,_and_i_received_it...       5          1\n",
       "B00009YUPS:don't_buy.__terrible_terrible_produc...       1          0\n",
       "B00005UKBG:nice_rack:charles_m._miller                   5          1\n",
       "B0009O5MWI:awesome_value!!_highly_recommend!:s....       5          1\n",
       "B00008RW8B:excellent_and_portable_memory_card_r...       5          1\n",
       "B00006HYUB:don't_risk_being_without_one!:theres...       1          0\n",
       "B00008SCFU:rcarrier:ronald_r._carrier                    5          1\n",
       "B00006IC4E:great_little_product!:jigga                   5          1\n",
       "B0001IXUEY:perfect_for_my_needs:vask                     5          1\n",
       "B000093IRC:great_successess_with_no_problems:sn...       5          1"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_data.to_csv('../predictions/electronics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
